# -*- coding: utf-8 -*-
"""rainfall_dashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10IW6R9yv_KBPqKQ6lT-H28tri9Zi9jh2
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from datetime import datetime

# Load the dataset
@st.cache_data  # Cache data to improve performance
def load_data(file_path):
    df = pd.read_csv(file_path)
    return df

# Preprocessing function (handle missing values and categorical features)
@st.cache_data
def preprocess_data(df):
    # Convert Date to datetime and extract year, month, day
    df['Date'] = pd.to_datetime(df['Date'])
    df['year'] = df['Date'].dt.year
    df['month'] = df['Date'].dt.month
    df['day'] = df['Date'].dt.day

    # Handle missing values using median for numerical columns
    for col in df.select_dtypes(include=np.number).columns:
        df[col] = df[col].fillna(df[col].median())

    # Convert RainToday and RainTomorrow to numerical (0 and 1)
    df['RainToday'] = df['RainToday'].map({'Yes': 1, 'No': 0}).fillna(0)
    df['RainTomorrow'] = df['RainTomorrow'].map({'Yes': 1, 'No': 0}).fillna(0)

    # Encode categorical features
    for col in df.select_dtypes(include='object').columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])

    return df

# Train the ANN model
@st.cache_data
def train_model(df):
    X = df.drop(['RainTomorrow', 'Date'], axis=1)
    y = df['RainTomorrow']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    model = MLPClassifier(random_state=42, max_iter=300)
    model.fit(X_train, y_train)
    return model, scaler, X_test, y_test

# Load data
file_path = "weatherAUS.csv"  # Use the local file path
df = load_data(file_path)

# Preprocess data
df = preprocess_data(df.copy())

# Train model
model, scaler, X_test, y_test = train_model(df)

# Streamlit app
st.title("Rainfall Prediction Dashboard")

# Sidebar filters
st.sidebar.header("Filters")

# Location filter
locations = df['Location'].unique()
selected_locations = st.sidebar.multiselect("Select Locations", locations, default=locations)
filtered_df = df[df['Location'].isin(selected_locations)]

# Date range filter
min_date = filtered_df['Date'].min().date()
max_date = filtered_df['Date'].max().date()
start_date = st.sidebar.date_input("Start Date", min_date)
end_date = st.sidebar.date_input("End Date", max_date)

# Convert selected dates to datetime objects
start_date = pd.to_datetime(start_date)
end_date = pd.to_datetime(end_date)

# Filter by date
filtered_df = filtered_df[(filtered_df['Date'] >= start_date) & (filtered_df['Date'] <= end_date)]

# Numerical feature filters
st.sidebar.header("Numerical Filters")
min_temp_threshold = st.sidebar.slider("Minimum Temperature Threshold", float(df['MinTemp'].min()), float(df['MinTemp'].max()), float(df['MinTemp'].min()))
max_temp_threshold = st.sidebar.slider("Maximum Temperature Threshold", float(df['MaxTemp'].min()), float(df['MaxTemp'].max()), float(df['MaxTemp'].max()))
filtered_df = filtered_df[(filtered_df['MinTemp'] >= min_temp_threshold) & (filtered_df['MaxTemp'] <= max_temp_threshold)]

# Display filtered data
st.subheader("Filtered Data")
st.dataframe(filtered_df)

# Visualizations
st.subheader("Visualizations")

# Rainfall distribution
st.subheader("Rainfall Distribution")
fig_rainfall = px.histogram(filtered_df, x="Rainfall", title="Rainfall Distribution")
st.plotly_chart(fig_rainfall)

# Average rainfall by location
avg_rainfall = filtered_df.groupby('Location')['Rainfall'].mean().reset_index()
fig_avg_rainfall = px.bar(avg_rainfall, x='Location', y='Rainfall', title='Average Rainfall by Location')
st.plotly_chart(fig_avg_rainfall)

# Prediction section
st.subheader("Rainfall Prediction")

# Prepare data for prediction
X = filtered_df.drop(['RainTomorrow', 'Date'], axis=1)
X_scaled = scaler.transform(X)

# Make predictions
y_pred = model.predict(X_scaled)

# Display predictions
st.write("Predictions:")
st.write(y_pred)

# Model Evaluation
st.subheader("Model Evaluation")
y_pred_test = model.predict(scaler.transform(X_test))
accuracy = accuracy_score(y_test, y_pred_test)
st.write(f"Accuracy on Test Set: {accuracy:.2f}")